{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5001_Kaggle_FirstTry.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Connectonnect to google drive"
      ],
      "metadata": {
        "id": "-FuHo5h6nRDq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRChBUGaf6Wi",
        "outputId": "e084210c-f8aa-4933-a9e1-672e26cac02c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "path = \"/content/drive/My Drive/5001_Kaggle/\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load the train dataset"
      ],
      "metadata": {
        "id": "iSR8oNsWnhcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lines = open(path + \"/train.csv\").readlines()\n",
        "\n",
        "data = []\n",
        "tick = 0\n",
        "for line in lines[1:]:\n",
        "  # sample No.39 have NAN features, remove it from the training set\n",
        "  if tick != 39:\n",
        "    data.append(line.strip().split(\",\")[1:])\n",
        "  tick = tick + 1\n",
        "\n",
        "print(data)\n",
        "\n",
        "# get the lables\n",
        "labels = []\n",
        "for i in data:\n",
        "  labels.append(int(i[-1]))\n",
        "\n",
        "print(labels)\n",
        "\n",
        "# get the features\n",
        "features = []\n",
        "for i in data:\n",
        "  tmp = []\n",
        "  # load the feature column No.0~No.8\n",
        "  for j in range(9):\n",
        "    tmp.append(float(i[j]))\n",
        "  # for feature column No.9(gender) create two binary feature to represent\n",
        "  if int(i[9]) == 1:\n",
        "    tmp.append(1)\n",
        "    tmp.append(0)\n",
        "  else:\n",
        "    tmp.append(0)\n",
        "    tmp.append(1)\n",
        "  # load the last feature column\n",
        "  tmp.append(float(i[10]))\n",
        "  features.append(tmp)\n",
        "\n",
        "print(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OV8rRvXCglga",
        "outputId": "54891028-4c32-433b-f04a-e91c06d8fdfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['3556.0', '2489.0', '265.19', '77.53', '176.55', '0.0', '4.2', '307.91', '52', '0', '7515.0', '1'], ['1906.0', '134.0', '1442.61', '551.9', '876.07', '112.1', '168.15', '1735.48', '20', '1', '1756.0', '0'], ['1586.0', '71.0', '1332.74', '684.2', '655.26', '244.95', '216.52', '1820.04', '28', '1', '1311.0', '0'], ['683.0', '94.0', '419.23', '255.8', '162.17', '72.05', '44.68', '538.22', '55', '1', '1443.0', '0'], ['1032.0', '71.0', '1102.72', '480.27', '625.3', '188.78', '130.77', '1427.97', '28', '1', '1542.0', '0'], ['495.0', '143.0', '1719.32', '885.94', '842.94', '271.42', '119.46', '2143.66', '42', '1', '1827.0', '1'], ['1517.0', '76.0', '813.73', '541.23', '276.28', '258.81', '82.81', '1179.27', '42', '0', '1784.0', '0'], ['2623.0', '126.0', '642.98', '329.66', '316.59', '167.89', '85.38', '899.51', '41', '0', '1620.0', '0'], ['2318.0', '150.0', '2679.19', '1120.76', '1415.44', '285.99', '342.02', '3347.78', '21', '1', '1642.0', '0'], ['1412.0', '243.0', '1177.19', '684.42', '490.5', '185.3', '67.22', '1441.06', '36', '1', '1213.0', '0'], ['2199.0', '3124.0', '511.57', '182.65', '331.33', '76.21', '73.27', '665.87', '51', '1', '4668.0', '1'], ['1100.0', '109.0', '1051.61', '458.99', '604.24', '878.04', '103.85', '2041.5', '52', '0', '1755.0', '0'], ['4145.0', '181.0', '871.71', '332.15', '529.29', '280.3', '111.92', '1268.04', '55', '0', '3285.0', '0'], ['2368.0', '119.0', '1353.36', '841.83', '531.45', '118.88', '71.97', '1547.43', '45', '1', '2587.0', '0'], ['632.0', '364.0', '709.52', '217.37', '478.15', '25.2', '46.9', '784.23', '39', '0', '1005.0', '1'], ['1614.0', '44.0', '1684.95', '1064.09', '623.42', '323.67', '110.17', '2150.38', '31', '1', '1924.0', '0'], ['1045.0', '124.0', '1179.07', '522.49', '661.78', '210.96', '93.63', '1498.11', '49', '1', '2075.0', '0'], ['751.0', '147.0', '980.73', '418.43', '558.83', '280.8', '129.28', '1400.25', '27', '0', '814.0', '1'], ['2506.0', '198.0', '1865.46', '792.76', '1096.75', '271.73', '166.75', '2329.09', '20', '1', '2096.0', '0'], ['403.0', '555.0', '313.48', '131.53', '182.69', '46.68', '7.9', '370.3', '40', '0', '2209.0', '1'], ['1607.0', '366.0', '521.65', '129.56', '390.63', '48.0', '40.9', '613.49', '37', '0', '4149.0', '1'], ['494.0', '201.0', '476.64', '235.84', '244.35', '72.55', '24.58', '578.96', '34', '1', '2392.0', '1'], ['860.0', '30.0', '782.02', '362.71', '365.66', '318.91', '110.73', '1215.6', '41', '1', '727.0', '0'], ['442.0', '360.0', '478.0', '240.0', '238.0', '97.0', '202.0', '777.0', '30', '0', '572.0', '1'], ['873.0', '77.0', '1078.6', '578.66', '499.93', '194.2', '253.25', '1573.28', '49', '1', '1591.0', '0'], ['537.0', '175.0', '218.13', '122.43', '96.93', '44.57', '51.94', '315.29', '50', '0', '3545.0', '1'], ['2088.0', '98.0', '962.3', '533.03', '459.72', '370.88', '142.89', '1477.31', '51', '1', '1599.0', '1'], ['2385.0', '138.0', '692.17', '155.06', '542.25', '254.08', '212.04', '1160.62', '51', '1', '1290.0', '0'], ['1247.0', '108.0', '1687.43', '612.79', '1077.23', '266.88', '248.09', '2205.64', '37', '1', '1673.0', '0'], ['239.0', '1330.0', '74.4', '36.61', '39.59', '86.41', '41.54', '209.25', '25', '1', '2248.0', '1'], ['1188.0', '82.0', '1108.99', '623.49', '483.6', '217.11', '213.32', '1547.02', '49', '1', '1947.0', '0'], ['1035.0', '87.0', '281.73', '124.41', '159.52', '69.13', '41.42', '394.64', '41', '0', '1651.0', '0'], ['1588.0', '92.0', '1442.63', '606.07', '840.82', '325.8', '485.86', '2282.03', '35', '0', '1365.0', '0'], ['1117.0', '336.0', '409.14', '206.74', '209.22', '37.87', '27.32', '475.57', '44', '1', '3190.0', '1'], ['821.0', '134.0', '1134.74', '741.0', '401.0', '459.72', '23.87', '1619.77', '41', '1', '1893.0', '0'], ['693.0', '245.0', '266.48', '103.61', '164.11', '147.95', '87.03', '504.15', '49', '0', '2175.0', '1'], ['1436.0', '76.0', '813.73', '541.23', '276.28', '258.81', '82.18', '1179.27', '42', '0', '1794.0', '0'], ['620.0', '472.0', '250.43', '150.39', '68.66', '64.08', '125.11', '439.84', '37', '1', '1527.0', '1'], ['1010.0', '1384.0', '570.13', '312.9', '233.84', '80.17', '31.18', '702.08', '56', '1', '5501.0', '1'], ['1024.0', '180.0', '858.48', '673.32', '185.61', '213.96', '50.06', '1129.59', '47', '0', '1953.0', '0'], ['222.0', '82.0', '1061.47', '423.27', '638.74', '246.18', '192.45', '1519.28', '33', '0', '1686.0', '0'], ['602.0', '98.0', '770.62', '499.81', '276.71', '214.92', '76.34', '1071.42', '49', '1', '1566.0', '0'], ['1679.0', '79.0', '483.21', '162.0', '309.0', '227.05', '101.09', '817.24', '39', '0', '4480.0', '0'], ['1365.0', '67.0', '841.88', '576.19', '269.21', '174.35', '62.8', '1082.11', '29', '1', '1830.0', '0'], ['1252.0', '47.0', '1365.68', '625.41', '695.11', '767.77', '62.84', '2215.92', '52', '0', '856.0', '0'], ['1893.0', '58.0', '1180.29', '353.75', '836.52', '514.4', '263.86', '1961.04', '60', '0', '1552.0', '0'], ['1947.0', '112.0', '428.97', '208.07', '214.66', '328.41', '76.99', '837.14', '51', '1', '2982.0', '0'], ['2773.0', '77.0', '393.85', '205.35', '184.68', '66.73', '59.31', '521.24', '39', '1', '2182.0', '0'], ['891.0', '500.0', '696.23', '337.9', '354.7', '219.81', '41.78', '969.64', '32', '0', '4089.0', '1'], ['421.0', '146.0', '788.15', '608.57', '186.13', '127.87', '229.11', '1166.51', '42', '0', '1516.0', '0'], ['171.0', '57.0', '3791.23', '2548.1', '1236.94', '489.83', '411.9', '4757.28', '27', '1', '72.0', '0'], ['1358.0', '69.0', '1114.49', '493.71', '619.57', '223.75', '105.79', '1520.04', '34', '0', '1615.0', '0'], ['1849.0', '61.0', '1237.55', '483.23', '788.77', '815.06', '245.7', '2308.28', '60', '0', '1443.0', '0'], ['1558.0', '611.0', '359.15', '148.65', '191.8', '20.62', '81.52', '467.04', '49', '1', '2189.0', '1'], ['1526.0', '515.0', '504.21', '193.91', '313.46', '42.04', '23.81', '572.73', '50', '0', '2058.0', '1'], ['1055.0', '87.0', '913.42', '410.52', '507.04', '77.46', '43.08', '1040.18', '48', '0', '1728.0', '1'], ['365.0', '248.0', '300.75', '195.07', '106.58', '13.42', '52.91', '371.3', '41', '1', '866.0', '1'], ['867.0', '61.0', '1444.66', '701.69', '758.53', '590.72', '43.98', '2098.31', '52', '0', '1148.0', '0'], ['631.0', '182.0', '675.1', '280.09', '386.57', '136.0', '56.23', '875.41', '29', '1', '3990.0', '0'], ['1037.0', '43.0', '1050.69', '549.2', '488.29', '185.85', '29.41', '1265.4', '50', '0', '1566.0', '0'], ['1047.0', '76.0', '1529.16', '664.01', '860.33', '249.25', '155.9', '1999.74', '34', '0', '1154.0', '0'], ['1238.0', '85.0', '1468.0', '702.0', '613.0', '604.0', '174.0', '2248.09', '31', '0', '1697.0', '0'], ['3040.0', '182.0', '2530.4', '1032.47', '1318.98', '257.34', '399.03', '3023.44', '20', '1', '1763.0', '0'], ['1190.0', '308.0', '435.76', '475.0', '337.0', '200.34', '42.69', '689.42', '53', '0', '2589.0', '1'], ['1156.0', '31.0', '1596.59', '731.99', '570.52', '206.39', '135.28', '1945.21', '33', '0', '673.0', '0'], ['731.0', '58.0', '723.25', '359.71', '366.95', '193.69', '95.35', '1015.7', '43', '0', '1040.0', '0'], ['1618.0', '1253.0', '947.1', '355.39', '593.51', '104.63', '77.12', '1131.1', '35', '0', '4946.0', '1'], ['2239.0', '126.0', '719.9', '462.77', '259.98', '142.42', '24.15', '895.71', '50', '0', '2330.0', '0'], ['1495.0', '125.0', '2910.03', '1431.78', '1517.81', '446.94', '401.45', '3817.75', '20', '1', '1793.0', '0'], ['1521.0', '105.0', '730.17', '176.61', '559.49', '253.74', '210.81', '1201.71', '51', '1', '2013.0', '0'], ['960.0', '106.0', '597.34', '280.85', '319.19', '157.3', '89.79', '848.44', '41', '0', '1550.0', '0'], ['969.0', '97.0', '546.62', '279.8', '267.73', '64.29', '81.8', '696.03', '54', '0', '1415.0', '0'], ['1047.0', '42.0', '1044.94', '370.37', '632.41', '188.1', '104.43', '1347.21', '34', '0', '781.0', '0'], ['953.0', '1233.0', '1192.83', '808.0', '293.0', '169.09', '71.08', '1437.01', '34', '1', '5022.0', '1'], ['1306.0', '114.0', '1298.62', '647.53', '608.43', '254.15', '90.64', '1648.75', '32', '0', '1589.0', '0'], ['365.0', '248.0', '300.75', '195.07', '106.58', '13.42', '52.91', '371.3', '41', '1', '866.0', '1'], ['1202.0', '258.0', '563.25', '288.73', '277.59', '306.77', '81.4', '962.17', '43', '0', '2027.0', '0'], ['523.0', '228.0', '669.71', '339.2', '330.12', '153.61', '108.99', '937.83', '41', '0', '1759.0', '0'], ['662.0', '127.0', '552.16', '219.15', '292.96', '58.36', '59.22', '671.75', '51', '1', '1350.0', '1'], ['1919.0', '105.0', '1187.33', '675.03', '477.04', '225.83', '100.23', '1546.19', '26', '0', '2601.0', '0'], ['2083.0', '95.0', '890.44', '403.58', '434.51', '97.56', '193.22', '1181.7', '41', '1', '1908.0', '0'], ['626.0', '68.0', '1771.57', '666.99', '1117.48', '360.21', '118.84', '2306.82', '42', '1', '1521.0', '0'], ['1237.0', '71.0', '1348.53', '428.09', '924.69', '120.02', '48.67', '1524.78', '56', '0', '1345.0', '0'], ['634.0', '1002.0', '1300.0', '558.0', '724.0', '67.0', '105.0', '1484.26', '34', '0', '2926.0', '1'], ['112.0', '884.0', '942.83', '378.49', '567.06', '116.77', '31.81', '1104.59', '33', '1', '2352.0', '1'], ['195.0', '213.0', '724.0', '364.0', '361.0', '18.0', '155.0', '897.0', '19', '1', '2445.0', '1']]\n",
            "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1]\n",
            "[[3556.0, 2489.0, 265.19, 77.53, 176.55, 0.0, 4.2, 307.91, 52.0, 0, 1, 7515.0], [1906.0, 134.0, 1442.61, 551.9, 876.07, 112.1, 168.15, 1735.48, 20.0, 1, 0, 1756.0], [1586.0, 71.0, 1332.74, 684.2, 655.26, 244.95, 216.52, 1820.04, 28.0, 1, 0, 1311.0], [683.0, 94.0, 419.23, 255.8, 162.17, 72.05, 44.68, 538.22, 55.0, 1, 0, 1443.0], [1032.0, 71.0, 1102.72, 480.27, 625.3, 188.78, 130.77, 1427.97, 28.0, 1, 0, 1542.0], [495.0, 143.0, 1719.32, 885.94, 842.94, 271.42, 119.46, 2143.66, 42.0, 1, 0, 1827.0], [1517.0, 76.0, 813.73, 541.23, 276.28, 258.81, 82.81, 1179.27, 42.0, 0, 1, 1784.0], [2623.0, 126.0, 642.98, 329.66, 316.59, 167.89, 85.38, 899.51, 41.0, 0, 1, 1620.0], [2318.0, 150.0, 2679.19, 1120.76, 1415.44, 285.99, 342.02, 3347.78, 21.0, 1, 0, 1642.0], [1412.0, 243.0, 1177.19, 684.42, 490.5, 185.3, 67.22, 1441.06, 36.0, 1, 0, 1213.0], [2199.0, 3124.0, 511.57, 182.65, 331.33, 76.21, 73.27, 665.87, 51.0, 1, 0, 4668.0], [1100.0, 109.0, 1051.61, 458.99, 604.24, 878.04, 103.85, 2041.5, 52.0, 0, 1, 1755.0], [4145.0, 181.0, 871.71, 332.15, 529.29, 280.3, 111.92, 1268.04, 55.0, 0, 1, 3285.0], [2368.0, 119.0, 1353.36, 841.83, 531.45, 118.88, 71.97, 1547.43, 45.0, 1, 0, 2587.0], [632.0, 364.0, 709.52, 217.37, 478.15, 25.2, 46.9, 784.23, 39.0, 0, 1, 1005.0], [1614.0, 44.0, 1684.95, 1064.09, 623.42, 323.67, 110.17, 2150.38, 31.0, 1, 0, 1924.0], [1045.0, 124.0, 1179.07, 522.49, 661.78, 210.96, 93.63, 1498.11, 49.0, 1, 0, 2075.0], [751.0, 147.0, 980.73, 418.43, 558.83, 280.8, 129.28, 1400.25, 27.0, 0, 1, 814.0], [2506.0, 198.0, 1865.46, 792.76, 1096.75, 271.73, 166.75, 2329.09, 20.0, 1, 0, 2096.0], [403.0, 555.0, 313.48, 131.53, 182.69, 46.68, 7.9, 370.3, 40.0, 0, 1, 2209.0], [1607.0, 366.0, 521.65, 129.56, 390.63, 48.0, 40.9, 613.49, 37.0, 0, 1, 4149.0], [494.0, 201.0, 476.64, 235.84, 244.35, 72.55, 24.58, 578.96, 34.0, 1, 0, 2392.0], [860.0, 30.0, 782.02, 362.71, 365.66, 318.91, 110.73, 1215.6, 41.0, 1, 0, 727.0], [442.0, 360.0, 478.0, 240.0, 238.0, 97.0, 202.0, 777.0, 30.0, 0, 1, 572.0], [873.0, 77.0, 1078.6, 578.66, 499.93, 194.2, 253.25, 1573.28, 49.0, 1, 0, 1591.0], [537.0, 175.0, 218.13, 122.43, 96.93, 44.57, 51.94, 315.29, 50.0, 0, 1, 3545.0], [2088.0, 98.0, 962.3, 533.03, 459.72, 370.88, 142.89, 1477.31, 51.0, 1, 0, 1599.0], [2385.0, 138.0, 692.17, 155.06, 542.25, 254.08, 212.04, 1160.62, 51.0, 1, 0, 1290.0], [1247.0, 108.0, 1687.43, 612.79, 1077.23, 266.88, 248.09, 2205.64, 37.0, 1, 0, 1673.0], [239.0, 1330.0, 74.4, 36.61, 39.59, 86.41, 41.54, 209.25, 25.0, 1, 0, 2248.0], [1188.0, 82.0, 1108.99, 623.49, 483.6, 217.11, 213.32, 1547.02, 49.0, 1, 0, 1947.0], [1035.0, 87.0, 281.73, 124.41, 159.52, 69.13, 41.42, 394.64, 41.0, 0, 1, 1651.0], [1588.0, 92.0, 1442.63, 606.07, 840.82, 325.8, 485.86, 2282.03, 35.0, 0, 1, 1365.0], [1117.0, 336.0, 409.14, 206.74, 209.22, 37.87, 27.32, 475.57, 44.0, 1, 0, 3190.0], [821.0, 134.0, 1134.74, 741.0, 401.0, 459.72, 23.87, 1619.77, 41.0, 1, 0, 1893.0], [693.0, 245.0, 266.48, 103.61, 164.11, 147.95, 87.03, 504.15, 49.0, 0, 1, 2175.0], [1436.0, 76.0, 813.73, 541.23, 276.28, 258.81, 82.18, 1179.27, 42.0, 0, 1, 1794.0], [620.0, 472.0, 250.43, 150.39, 68.66, 64.08, 125.11, 439.84, 37.0, 1, 0, 1527.0], [1010.0, 1384.0, 570.13, 312.9, 233.84, 80.17, 31.18, 702.08, 56.0, 1, 0, 5501.0], [1024.0, 180.0, 858.48, 673.32, 185.61, 213.96, 50.06, 1129.59, 47.0, 0, 1, 1953.0], [222.0, 82.0, 1061.47, 423.27, 638.74, 246.18, 192.45, 1519.28, 33.0, 0, 1, 1686.0], [602.0, 98.0, 770.62, 499.81, 276.71, 214.92, 76.34, 1071.42, 49.0, 1, 0, 1566.0], [1679.0, 79.0, 483.21, 162.0, 309.0, 227.05, 101.09, 817.24, 39.0, 0, 1, 4480.0], [1365.0, 67.0, 841.88, 576.19, 269.21, 174.35, 62.8, 1082.11, 29.0, 1, 0, 1830.0], [1252.0, 47.0, 1365.68, 625.41, 695.11, 767.77, 62.84, 2215.92, 52.0, 0, 1, 856.0], [1893.0, 58.0, 1180.29, 353.75, 836.52, 514.4, 263.86, 1961.04, 60.0, 0, 1, 1552.0], [1947.0, 112.0, 428.97, 208.07, 214.66, 328.41, 76.99, 837.14, 51.0, 1, 0, 2982.0], [2773.0, 77.0, 393.85, 205.35, 184.68, 66.73, 59.31, 521.24, 39.0, 1, 0, 2182.0], [891.0, 500.0, 696.23, 337.9, 354.7, 219.81, 41.78, 969.64, 32.0, 0, 1, 4089.0], [421.0, 146.0, 788.15, 608.57, 186.13, 127.87, 229.11, 1166.51, 42.0, 0, 1, 1516.0], [171.0, 57.0, 3791.23, 2548.1, 1236.94, 489.83, 411.9, 4757.28, 27.0, 1, 0, 72.0], [1358.0, 69.0, 1114.49, 493.71, 619.57, 223.75, 105.79, 1520.04, 34.0, 0, 1, 1615.0], [1849.0, 61.0, 1237.55, 483.23, 788.77, 815.06, 245.7, 2308.28, 60.0, 0, 1, 1443.0], [1558.0, 611.0, 359.15, 148.65, 191.8, 20.62, 81.52, 467.04, 49.0, 1, 0, 2189.0], [1526.0, 515.0, 504.21, 193.91, 313.46, 42.04, 23.81, 572.73, 50.0, 0, 1, 2058.0], [1055.0, 87.0, 913.42, 410.52, 507.04, 77.46, 43.08, 1040.18, 48.0, 0, 1, 1728.0], [365.0, 248.0, 300.75, 195.07, 106.58, 13.42, 52.91, 371.3, 41.0, 1, 0, 866.0], [867.0, 61.0, 1444.66, 701.69, 758.53, 590.72, 43.98, 2098.31, 52.0, 0, 1, 1148.0], [631.0, 182.0, 675.1, 280.09, 386.57, 136.0, 56.23, 875.41, 29.0, 1, 0, 3990.0], [1037.0, 43.0, 1050.69, 549.2, 488.29, 185.85, 29.41, 1265.4, 50.0, 0, 1, 1566.0], [1047.0, 76.0, 1529.16, 664.01, 860.33, 249.25, 155.9, 1999.74, 34.0, 0, 1, 1154.0], [1238.0, 85.0, 1468.0, 702.0, 613.0, 604.0, 174.0, 2248.09, 31.0, 0, 1, 1697.0], [3040.0, 182.0, 2530.4, 1032.47, 1318.98, 257.34, 399.03, 3023.44, 20.0, 1, 0, 1763.0], [1190.0, 308.0, 435.76, 475.0, 337.0, 200.34, 42.69, 689.42, 53.0, 0, 1, 2589.0], [1156.0, 31.0, 1596.59, 731.99, 570.52, 206.39, 135.28, 1945.21, 33.0, 0, 1, 673.0], [731.0, 58.0, 723.25, 359.71, 366.95, 193.69, 95.35, 1015.7, 43.0, 0, 1, 1040.0], [1618.0, 1253.0, 947.1, 355.39, 593.51, 104.63, 77.12, 1131.1, 35.0, 0, 1, 4946.0], [2239.0, 126.0, 719.9, 462.77, 259.98, 142.42, 24.15, 895.71, 50.0, 0, 1, 2330.0], [1495.0, 125.0, 2910.03, 1431.78, 1517.81, 446.94, 401.45, 3817.75, 20.0, 1, 0, 1793.0], [1521.0, 105.0, 730.17, 176.61, 559.49, 253.74, 210.81, 1201.71, 51.0, 1, 0, 2013.0], [960.0, 106.0, 597.34, 280.85, 319.19, 157.3, 89.79, 848.44, 41.0, 0, 1, 1550.0], [969.0, 97.0, 546.62, 279.8, 267.73, 64.29, 81.8, 696.03, 54.0, 0, 1, 1415.0], [1047.0, 42.0, 1044.94, 370.37, 632.41, 188.1, 104.43, 1347.21, 34.0, 0, 1, 781.0], [953.0, 1233.0, 1192.83, 808.0, 293.0, 169.09, 71.08, 1437.01, 34.0, 1, 0, 5022.0], [1306.0, 114.0, 1298.62, 647.53, 608.43, 254.15, 90.64, 1648.75, 32.0, 0, 1, 1589.0], [365.0, 248.0, 300.75, 195.07, 106.58, 13.42, 52.91, 371.3, 41.0, 1, 0, 866.0], [1202.0, 258.0, 563.25, 288.73, 277.59, 306.77, 81.4, 962.17, 43.0, 0, 1, 2027.0], [523.0, 228.0, 669.71, 339.2, 330.12, 153.61, 108.99, 937.83, 41.0, 0, 1, 1759.0], [662.0, 127.0, 552.16, 219.15, 292.96, 58.36, 59.22, 671.75, 51.0, 1, 0, 1350.0], [1919.0, 105.0, 1187.33, 675.03, 477.04, 225.83, 100.23, 1546.19, 26.0, 0, 1, 2601.0], [2083.0, 95.0, 890.44, 403.58, 434.51, 97.56, 193.22, 1181.7, 41.0, 1, 0, 1908.0], [626.0, 68.0, 1771.57, 666.99, 1117.48, 360.21, 118.84, 2306.82, 42.0, 1, 0, 1521.0], [1237.0, 71.0, 1348.53, 428.09, 924.69, 120.02, 48.67, 1524.78, 56.0, 0, 1, 1345.0], [634.0, 1002.0, 1300.0, 558.0, 724.0, 67.0, 105.0, 1484.26, 34.0, 0, 1, 2926.0], [112.0, 884.0, 942.83, 378.49, 567.06, 116.77, 31.81, 1104.59, 33.0, 1, 0, 2352.0], [195.0, 213.0, 724.0, 364.0, 361.0, 18.0, 155.0, 897.0, 19.0, 1, 0, 2445.0]]\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Data normalization(optional)"
      ],
      "metadata": {
        "id": "sHrzEt9DoyvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_X = scaler.fit_transform(features)"
      ],
      "metadata": {
        "id": "QoRDquohZQPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Train classifier"
      ],
      "metadata": {
        "id": "cDcujfMNpFFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import math\n",
        "\n",
        "model = LogisticRegression(solver='liblinear', random_state=0, class_weight=\"balanced\")\n",
        "# model = svm.SVC(C=1,kernel='rbf',gamma=10,decision_function_shape='ovo') \n",
        "# model = RandomForestClassifier(n_estimators=10, max_features=int(math.sqrt(12)), max_depth=None, min_samples_split=2, bootstrap=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPjewj4rZkok",
        "outputId": "1e15b2ec-206a-43b4-b7ca-dc90e0214842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_features=3, n_estimators=10)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(solver='liblinear', random_state=0)\n",
        "model.fit(features, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rxnAuMybjiq",
        "outputId": "ed0fa67a-ead4-4b8c-bab7-34549a14e38b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=0, solver='liblinear')"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Load the test dataset,  do preprocessing as train dataset\n"
      ],
      "metadata": {
        "id": "C4avDmUXpdPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lines = open(path + \"/test.csv\").readlines()\n",
        "\n",
        "data = []\n",
        "\n",
        "for line in lines[1:]:\n",
        "  data.append(line.strip().split(\",\")[1:])\n",
        "\n",
        "features = []\n",
        "for i in data:\n",
        "  tmp = []\n",
        "  for j in range(9):\n",
        "    tmp.append(float(i[j]))\n",
        "  if int(i[9]) == 1:\n",
        "    tmp.append(1)\n",
        "    tmp.append(0)\n",
        "  else:\n",
        "    tmp.append(0)\n",
        "    tmp.append(1)\n",
        "  tmp.append(float(i[10]))\n",
        "  features.append(tmp)"
      ],
      "metadata": {
        "id": "rt1MxmspbZG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Do prediction"
      ],
      "metadata": {
        "id": "APA7ydS_pvA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# features = scaler.transform(features)\n",
        "y_pred_test = model.predict(features)\n",
        "print(len(y_pred_test))\n",
        "y_pred_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9jM0m2ha_pL",
        "outputId": "54e0e1a4-0659-4aac-d7ab-f60505bfe914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Write the result to sample_submission"
      ],
      "metadata": {
        "id": "7Z5MUGOAp4Ga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(path + \"/sample_submission.csv\", \"w\") as f:\n",
        "  f.write(\"id,label\"  + \"\\n\")\n",
        "  for i in range(len(y_pred_test)):\n",
        "    f.write(str(i) + \",\" + str(y_pred_test[i])  + \"\\n\")\n",
        "f.close()"
      ],
      "metadata": {
        "id": "KY4QWnNOcA7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Result\n",
        "By using LR, the best result is 96.51%, which means only has 2 errors. Combining all the results from different classifiers, we can see models mostly have disagreed on test samples from N0.0 to No.9. Manually fix the misclassified test samples by changing the prediction labels of the first 10 test samples, we can easily achieve 100% acc. Then we can add test data into further training."
      ],
      "metadata": {
        "id": "Cnr3ALWgqJBr"
      }
    }
  ]
}